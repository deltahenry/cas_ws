依下列描述產生claude cli 能理解的specification.md檔
這是在一個ros2的資料夾下，目前要新增2個python package
在src下方新增2個package
1. realsense_camera_driver
以python撰寫
驅動realsense並將取得rgb的圖
以讀取parameter.yaml的方式，決定連接哪個型號，如D405，D435
以讀取parameter.yaml的方式，連接幾個camera，如1,2,3......
以讀取parameter.yaml的方式，決定FPS, 預設15
啟動node 後以10Hz發布topic /camera_image, type CV.MAT

2. vision_compensation
建立一個subsribe 訂閱/detection_cmd, type string , 及其callback function, detection_cmd_callback
建立一個subsribe 訂閱/camera_image, type CV.MAT , 進callback function後將其存在class 的image_now裡面
建立發布/compensate_pose 可以讓其他的node訂閱，並以以下方式解包
def compensate_pose_callback(self, msg: Float32MultiArray):
    if len(msg.data) >= 2:
        X, Z = msg.data[:2]
        self.get_logger().info(f"Received compensation: X={X:.2f}, Z={Z:.2f}")
    
顯示目前照片    
在detection_cmd_callback裡面監控指令兩個指令都要發布/image_golden_with_corner, /image_now_with_corner
 msg.data == "start_detect" 呼叫x, z = compensate_cabinet(image_golden, image_now);
 比較golden sample和目前取得的image, 輸出x和z 
 校正係數: X_out *= 0.53, Z_out *= 0.18
golden sample 檔名 = ~/image_sample2D_golden(x=0,z=112).png

 msg.data == "start_detect_0" 呼叫x, z = compensate_cabinet(image_golden, image_test);
golden sample 檔名 = ~/image_sample2D_golden(x=0,z=112).png
image_test 檔名 = ~/image_sample2D_golden(x=0,z=112).png
 校正係數: X_out *= 0.53, Z_out *= 0.18

msg.data == "start_test"       呼叫x, z = compensate_cabinet_test(image_golden, image_test);
 比較golden sample和存好檔的圖image_test, 輸出x和z 
 校正係數: X_out *= 0.53, Z_out *= 0.18
golden sample 檔名 = ~/image_sample/2D_golden(x=0,z=112).png
image_test 檔名 = ~/image_sample/2D(x=25,z=117).png
 
 msg.data == "save_image"       
將圖片存成png檔，檔名為時間 如 2025_0908_173026.png
 
翻譯ultility 裡的vision.cs 和 example.cs成vision.py 和example.cs放在vision_compensation資料夾下
將CompareAverageCornersAndDraw命名為compensate_cabinet, 並保留所有輸入和輸出
建立class BlobEdgePipeline 放調整參數
把參數寫在vision_parameter.yaml裡面
    
增加一個show_image_node 訂閱 image_golden_with_corner, /image_now_with_corner
在收到的時候把這2張圖畫出來
顯示在同一個視窗上，分為上下2格

產生一個launch file
