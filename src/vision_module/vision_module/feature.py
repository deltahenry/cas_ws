import cv2
import os
import re
import pyrealsense2 as rs
import numpy as np

# ================== å¯èª¿åƒæ•¸ ==================
# ç›¸æ©Ÿé–å®šï¼ˆå»ºè­° Trueï¼šé¿å…ç•«é¢å¿½æš—å¿½äº®ï¼‰
LOCK_CAMERA_PARAMS = True
EXPOSURE_US = 1200.0   # æ›å…‰(å¾®ç§’) â†’ æš—å°±åŠ å¤§(800~4000)ï¼Œå¤ªå¤§æœƒæ‹–å½±/äº®æ–‘
GAIN       = 32.0      # å¢ç›Š       â†’ æš—å¯æé«˜(16~96)ï¼Œå¤ªé«˜æœƒå™ªé»
WHITE_BAL  = 4600.0    # ç™½å¹³è¡¡(K)  â†’ å®¤å…§ 4000~5000 å¸¸è¦‹

# å½±åƒå‰è™•ç†ï¼ˆæŠ—å…‰ç…§ï¼‰
GAMMA = 1.4            # Gamma æ ¡æ­£ï¼›>1 æäº®æš—éƒ¨ï¼ˆ1.2~1.8 å¸¸ç”¨ï¼‰
CLAHE_CLIP = 2.0       # CLAHE å°æ¯”é™åˆ¶(1.5~3.0)
CLAHE_TILE = (8, 8)    # CLAHE å€å¡Šå¤§å°
BLUR_KSIZE = 5         # å»å™ªé«˜æ–¯æ ¸(å¥‡æ•¸ 3/5/7)

USE_BLACKHAT = True    # é»‘å¸½å¢å¼·æš—ç´°ç·šï¼ˆL å‹é»‘ç·šæ›´æ˜é¡¯ï¼‰
BLACKHAT_K   = 9       # é»‘å¸½æ ¸å¤§å°(å¥‡æ•¸ 7/9/11)

# Auto-Cannyï¼ˆä¾å½±åƒä¸­ä½æ•¸è¨ˆç®—é–€æª»ï¼‰
SIGMA = 0.33           # é‚Šç·£é‡çš„æ§åˆ¶ï¼›è¶Šå¤§æŠ“åˆ°çš„é‚Šè¶Šå¤š(0.25~0.45)

# é‚Šç·£ç´°ç·šåŠ ç²—ï¼ˆé¿å…å°èºçµ²é‚Šç·£æ–·è£‚ï¼‰
USE_DILATE   = True
DILATE_KSIZE = 3       # 3/5ï¼›éå¤§æœƒå¤ªç²—ç³™
DILATE_ITER  = 1
# ===========================================================

# ===== å›ºå®šå„²å­˜é¡å‹èˆ‡è³‡æ–™å¤¾ =====
mode = 'feature_shape'
template_dir = os.path.join(os.path.dirname(__file__), f'template_{mode}')
os.makedirs(template_dir, exist_ok=True)

def next_index(dir_path, prefix):
    """å›å‚³ prefix_#.png çš„ä¸‹ä¸€å€‹å¯ç”¨ç·¨è™Ÿ"""
    pat = re.compile(rf'^{re.escape(prefix)}_(\d+)\.png$')
    max_idx = -1
    for f in os.listdir(dir_path):
        m = pat.match(f)
        if m:
            max_idx = max(max_idx, int(m.group(1)))
    return max_idx + 1

template_count = next_index(template_dir, mode)

# ===== RealSense åˆå§‹åŒ–ï¼ˆRGBï¼‰=====
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
profile = pipeline.start(config)

def lock_rgb_settings():
    """é—œè‡ªå‹•æ›å…‰/ç™½å¹³è¡¡ä¸¦è¨­æ‰‹å‹•å€¼ï¼ˆRGB Camera ä¸Šï¼‰"""
    try:
        dev = profile.get_device()
        for s in dev.query_sensors():
            if 'RGB Camera' in s.get_info(rs.camera_info.name):
                if s.supports(rs.option.enable_auto_exposure):
                    s.set_option(rs.option.enable_auto_exposure, 0)
                if s.supports(rs.option.exposure):
                    s.set_option(rs.option.exposure, float(EXPOSURE_US))
                if s.supports(rs.option.gain):
                    s.set_option(rs.option.gain, float(GAIN))
                if s.supports(rs.option.enable_auto_white_balance):
                    s.set_option(rs.option.enable_auto_white_balance, 0)
                if s.supports(rs.option.white_balance):
                    s.set_option(rs.option.white_balance, float(WHITE_BAL))
                print(f"ğŸ”’ lock camera: exp={EXPOSURE_US}us, gain={GAIN}, wb={WHITE_BAL}K")
                break
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•é–å®šç›¸æ©Ÿåƒæ•¸ï¼š{e}")

if LOCK_CAMERA_PARAMS:
    lock_rgb_settings()

# ========== å½±åƒå‰è™•ç†ï¼ˆæŠ—å…‰ç…§ï¼‰ ==========
clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP, tileGridSize=CLAHE_TILE)

def gamma_correct(gray, g):
    """å¿«é€Ÿ Gamma LUT"""
    g = max(0.4, min(2.5, float(g)))
    table = ((np.arange(256)/255.0) ** (1.0/g) * 255.0).astype(np.uint8)
    return cv2.LUT(gray, table)

def preprocess_to_edges(bgr):
    """
    æŠ—å…‰ç…§ + Auto-Cannyï¼š
      BGR â†’ ç°éš â†’ Gamma â†’ CLAHE â†’ GaussianBlur
      â†’ (é¸) BlackHat å¢å¼·æš—ç´°ç·š â†’ Auto-Canny â†’ (é¸) è†¨è„¹åŠ ç²—
    """
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
    gray = gamma_correct(gray, GAMMA)
    gray = clahe.apply(gray)
    blur = cv2.GaussianBlur(gray, (BLUR_KSIZE, BLUR_KSIZE), 0)

    if USE_BLACKHAT:
        k = cv2.getStructuringElement(cv2.MORPH_RECT, (BLACKHAT_K, BLACKHAT_K))
        bh = cv2.morphologyEx(blur, cv2.MORPH_BLACKHAT, k)
        blur = cv2.add(blur, bh)

    v = np.median(blur)
    lower = int(max(0, (1.0 - SIGMA) * v))
    upper = int(min(255, (1.0 + SIGMA) * v))
    edges = cv2.Canny(blur, lower, upper, L2gradient=True, apertureSize=3)

    if USE_DILATE and DILATE_KSIZE > 0 and DILATE_ITER > 0:
        dk = cv2.getStructuringElement(cv2.MORPH_RECT, (DILATE_KSIZE, DILATE_KSIZE))
        edges = cv2.dilate(edges, dk, iterations=DILATE_ITER)
    return edges

# ===== ROI æ»‘é¼ äº’å‹• =====
roi = None
drag = False
ix, iy = -1, -1
def mouse_callback(event, x, y, flags, param):
    global ix, iy, roi, drag
    if event == cv2.EVENT_LBUTTONDOWN:
        ix, iy = x, y; drag = True
    elif event == cv2.EVENT_MOUSEMOVE and drag:
        roi = (ix, iy, x, y)
    elif event == cv2.EVENT_LBUTTONUP:
        roi = (ix, iy, x, y); drag = False

cv2.namedWindow("Canny View", cv2.WINDOW_NORMAL)
cv2.setMouseCallback("Canny View", mouse_callback)
print("ğŸŸ¦ åœ¨ Canny è¦–åœ–æ‹–æ›³æ¡†é¸ L å‹é»‘ç·šï¼›S å„²å­˜ã€ESC é›¢é–‹ã€‚")

try:
    while True:
        frames = pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        if not color_frame:
            continue

        bgr = np.asanyarray(color_frame.get_data())

        # â€”â€” æ ¸å¿ƒæ›´å‹•ï¼šç”¨æŠ—å…‰ç…§å‰è™•ç† + Auto-Canny å–ä»£å›ºå®š Canny(50,150)
        edges = preprocess_to_edges(bgr)

        display = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
        if roi:
            x1, y1, x2, y2 = roi
            cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 255), 2)

        cv2.putText(display, "Drag ROI | S: save | ESC: quit",
                    (10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)

        cv2.imshow("Canny View", display)
        key = cv2.waitKey(1) & 0xFF

        if key == 27:  # ESC
            break
        elif key == ord('s') and roi:
            h_img, w_img = edges.shape[:2]
            x1, y1, x2, y2 = roi
            # å¤¾ä½é‚Šç•Œä¸¦æ’åº
            x1, x2 = sorted([max(0, min(w_img-1, x1)), max(0, min(w_img-1, x2))])
            y1, y2 = sorted([max(0, min(h_img-1, y1)), max(0, min(h_img-1, y2))])
            if x2 - x1 < 5 or y2 - y1 < 5:
                print("âš ï¸ ROI å¤ªå°ï¼Œæœªå„²å­˜ã€‚"); continue

            cropped = edges[y1:y2, x1:x2]
            save_path = os.path.join(template_dir, f"{mode}_{template_count}.png")
            if cv2.imwrite(save_path, cropped):
                print(f"âœ… æ¨¡æ¿å„²å­˜æˆåŠŸï¼š{save_path}")
                template_count += 1
                roi = None

finally:
    pipeline.stop()
    cv2.destroyAllWindows()
